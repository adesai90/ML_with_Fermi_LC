{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5916c5de-9283-49cc-a0fb-6d2709559f96",
   "metadata": {},
   "source": [
    "## Code Description:\n",
    "\n",
    "This code will use the downloaded Fermi LAT lightcurves from the LC repository.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f33d177-76f7-4265-b844-42acf2652010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Fermi-LAT Light Curve Repository Toolkit v0.1.0\n",
      "Support Contact: Daniel Kocevski (daniel.kocevski@nasa.gov)\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyLCR\n",
    "from astropy.io import fits\n",
    "import pickle\n",
    "import datetime\n",
    "from codes_from_pylcr import *\n",
    "\n",
    "import joblib\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For training:\n",
    "import xgboost as xgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "930d385c-1991-4659-9076-5bc5375b5d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/aadesai1/Desktop/In_use/ML_work/Fermi_amego_alert_project/Fermi_Sample/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eeb501-1363-416d-b104-b304050d6483",
   "metadata": {},
   "source": [
    "### Note that this code uses the Fermi LC saved as a pickle file in the following format:\n",
    "  [array1],[array2],[array3],[array4]\n",
    "-  array1 = [timebins_detections,flux] --------------> xvals = timebins_detections\n",
    "-  array2 = [x_errors,np.transpose(flux_error)]------> xvals = timebins_detections\n",
    "-  array3 = [timebins_upperlimits,flux_upper_limit]--> xvals = timebins_upperlimits\n",
    "-  array4 = [timebins,ts] ----------------------------> xvals = timebins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20e9d5d0-2f5d-4461-b225-877299bd2185",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_fermi_lcs = glob.glob(f'lc_downloaded_data/*.pickle')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e63e8a5-21a2-4437-ae3a-adffe770ab53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 308 54686.5 \n",
      "\n",
      "1 82 55050.49998842592 \n",
      "\n",
      "2 104 54756.5 \n",
      "\n",
      "3 77 54819.5 \n",
      "\n",
      "4 405 54686.5 \n",
      "\n",
      "5 136 54707.5 \n",
      "\n",
      "6 216 54686.5 \n",
      "\n",
      "7 150 54693.5 \n",
      "\n",
      "8 206 54728.5 \n",
      "\n",
      "9 388 54686.5 \n",
      "\n",
      "10 206 54693.5 \n",
      "\n",
      "11 118 54686.5 \n",
      "\n",
      "12 161 54714.5 \n",
      "\n",
      "13 313 54686.5 \n",
      "\n",
      "14 134 54742.5 \n",
      "\n",
      "15 84 54840.49998842592 \n",
      "\n",
      "16 362 54686.5 \n",
      "\n",
      "17 216 54707.5 \n",
      "\n",
      "18 228 54686.5 \n",
      "\n",
      "19 159 54735.5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for indi_i_val in range(len(saved_fermi_lcs)):\n",
    "    with open(saved_fermi_lcs[indi_i_val], 'rb') as handle:\n",
    "        loaded_fermi_lc = pickle.load(handle)\n",
    "\n",
    "    \n",
    "    all_times=loaded_fermi_lc[0][0]\n",
    "    all_flux_with_ul=loaded_fermi_lc[0][1]\n",
    "    print(indi_i_val,len(all_times),np.amin(all_times), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3c2006a-6186-4e74-9560-73ee301e81b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new feature files or sue old ones:\n",
    "make_feature_files=True\n",
    "\n",
    "# Set Debug Flag\n",
    "debug_this=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32c7f00c-fbe0-4aa1-a4f6-841fb80f18a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for indi_i_val in range(len(saved_fermi_lcs)):\n",
    "    if make_feature_files==False:\n",
    "        continue\n",
    "    with open(saved_fermi_lcs[indi_i_val], 'rb') as handle:\n",
    "        loaded_fermi_lc = pickle.load(handle)\n",
    "\n",
    "    all_times=loaded_fermi_lc[0][0]\n",
    "    all_flux_with_ul=loaded_fermi_lc[0][1]\n",
    "    if debug_this==True:\n",
    "        all_times=loaded_fermi_lc[3][0]\n",
    "        all_flux_with_ul=[]\n",
    "        for time in all_times:\n",
    "            found_flux=0\n",
    "            for index_t_det in range(len(loaded_fermi_lc[0][0])):\n",
    "                if time==loaded_fermi_lc[0][0][index_t_det]:\n",
    "                    all_flux_with_ul.append(loaded_fermi_lc[0][1][index_t_det])\n",
    "                    found_flux=1\n",
    "            if found_flux==0:\n",
    "                all_flux_with_ul.append(0)\n",
    "        print(np.amax(np.asarray(all_flux_with_ul)*1e7),np.amin(np.asarray(all_flux_with_ul)*1e7))  \n",
    "        plt.plot(all_times,np.asarray(all_flux_with_ul)*1e7)     \n",
    "    \n",
    "    df = pd.DataFrame.from_records(np.transpose([all_times,np.asarray(all_flux_with_ul)*1e7]), columns=['#MJD','flux'])\n",
    "    df.set_index('#MJD', inplace=True) #This replaces the index with the MJD value\n",
    "\n",
    "    if debug_this==True:\n",
    "        # Display the DataFrame\n",
    "        df.plot(figsize=(10,5))\n",
    "    \n",
    "    batch_df = pd.DataFrame()\n",
    "\n",
    "    # Lagging features\n",
    "    batch_df['lag_1'] = df['flux'].shift(1) # Prediction 0 Use numdays: 1 day 0-1 = 1\n",
    "    batch_df['lag_4'] = df['flux'].shift(4) # Prediction 3 Use numdays: 7 day 3-7 = 4\n",
    "    batch_df['lag_5'] = df['flux'].shift(5) # Prediction 2 Use numdays: -7 day 2-7 = 5\n",
    "    batch_df['lag_6'] = df['flux'].shift(6) # Prediction 1 Use numdays: -7 day 1-7 = 6\n",
    "\n",
    "    batch_df['lag_11'] = df['flux'].shift(11) # Prediction 3 Use numdays: -14 day 3-14 = 11\n",
    "    batch_df['lag_12'] = df['flux'].shift(12) # Prediction 2 Use numdays: -14 day 2-14 = 12\n",
    "    batch_df['lag_13'] = df['flux'].shift(13) # Prediction 1 Use numdays: -14 day 1-14 = 13\n",
    "\n",
    "\n",
    "    # Rolling statistics\n",
    "    batch_df['rolling_mean_7'] = df['flux'].rolling(window=7).mean().round(2)\n",
    "    batch_df['rolling_std_7'] = df['flux'].rolling(window=7).std().round(2)\n",
    "\n",
    "    # Inspect target variable - it's actually 3!\n",
    "\n",
    "    # Lagging target variable\n",
    "    batch_df['target_1d'] = df['flux'].shift(-1) # Next day\n",
    "    batch_df['target_2d'] = df['flux'].shift(-2) # Second-next day\n",
    "    batch_df['target_3d'] = df['flux'].shift(-3) # Third-next day\n",
    "\n",
    "    # Run predictions with all three models\n",
    "\n",
    "    predictions_ls = [] # list to store predictions\n",
    "    batch_df = batch_df.dropna()\n",
    "\n",
    "    corr = batch_df.corr()\n",
    "    corr.style.background_gradient(cmap='coolwarm')\n",
    "    features_df = batch_df[[\"lag_1\", \"lag_4\", \"lag_5\", \"lag_6\", \"lag_11\", \"lag_12\", \"lag_13\", \"rolling_mean_7\", \"rolling_std_7\"]] \n",
    "    # Directory for feature store\n",
    "    directory = \"feature_store\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "    id = \"v1\"\n",
    "    features_df.to_csv(f'{directory}/{saved_fermi_lcs[indi_i_val][-24:-7]}_features_{id}.csv')\n",
    "    #targets_df = batch_df[[\"target_1d\", \"target_2d\", \"target_3d\", \"target_9d\"]] \n",
    "    targets_df = batch_df[[\"target_1d\", \"target_2d\", \"target_3d\"]] \n",
    "    targets_df.to_csv(f'{directory}/{saved_fermi_lcs[indi_i_val][-24:-7]}_targets_{id}.csv')\n",
    "    del loaded_fermi_lc,targets_df,batch_df,corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34b41d0b-c408-47f0-b660-aa3a93afb308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the marker to seperate of the data for learning and prediction:\n",
    "#leave_number_indices = -40\n",
    "\n",
    "# Make new feature files or sue old ones:\n",
    "make_training_files=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58a917eb-3c8f-4c82-ae84-ff793cb22b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(fermi_lc_file,directory,id):\n",
    "\n",
    "    \n",
    "    X_train = pd.read_csv(f'{directory}/{fermi_lc_file}_features_{id}.csv')\n",
    "    X_train.set_index('#MJD', inplace=True) #This replaces the index with the MJD value\n",
    "    if len(X_train)/3>=40:\n",
    "        leave_number_indices = -40\n",
    "    else:\n",
    "        leave_number_indices = -1*int(len(X_train)/3)\n",
    "    print(len(X_train))\n",
    "    X_train_mod = X_train.head(leave_number_indices) # save some rows for later\n",
    "    X_train_mod\n",
    "\n",
    "    targets_df = pd.read_csv(f'{directory}/{fermi_lc_file}_targets_{id}.csv')\n",
    "    targets_df.set_index('#MJD', inplace=True) #This replaces the index with the MJD value\n",
    "    targets_df_mod = targets_df.head(leave_number_indices) # save some rows for later \n",
    "    targets_df_mod\n",
    "\n",
    "    # turn into a list\n",
    "    y_train_ls= []\n",
    "    for target in targets_df_mod.columns:\n",
    "      y_train_ls.append(targets_df_mod[target])\n",
    "\n",
    "    # Loop through targets - train one model for each target variable\n",
    "    cv_results_ls = []\n",
    "    for y_train in y_train_ls:\n",
    "\n",
    "      # Prepare the DMatrix which is required by XGBoost\n",
    "      dtrain = xgb.DMatrix(data=X_train_mod, label=y_train)\n",
    "\n",
    "      # Define XGBoost parameters\n",
    "      params = {\n",
    "        #'max_depth': 6,\n",
    "        #'min_child_weight': 1,\n",
    "        'eta': 0.01,\n",
    "        #'subsample': 1,\n",
    "        #'colsample_bytree': 1,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse'\n",
    "      }\n",
    "\n",
    "      # Perform cross-validation\n",
    "      cv_results = xgb.cv(\n",
    "          params=params,\n",
    "          dtrain=dtrain,\n",
    "          num_boost_round=100,\n",
    "          early_stopping_rounds=5,\n",
    "          metrics='rmse',\n",
    "          as_pandas=True,\n",
    "          seed=123\n",
    "      )\n",
    "      cv_results_ls.append(cv_results)\n",
    "      # Show the last mean RMSE as a measure of final performance\n",
    "      print(f\"Last mean RMSE: {cv_results['test-rmse-mean'][-1:]}\")\n",
    "\n",
    "    if debug_this==True:\n",
    "      plt.figure(figsize=(10, 6))\n",
    "\n",
    "      for idx, cv_results in enumerate(cv_results_ls):\n",
    "          plt.plot(cv_results['test-rmse-mean'], label=f'CV Run {idx+1}')\n",
    "\n",
    "      plt.title('Test RMSE Through Iterations')\n",
    "      plt.xlabel('Number of Boosting Rounds')\n",
    "      plt.ylabel('Mean RMSE')\n",
    "      plt.legend()\n",
    "      plt.show()\n",
    "\n",
    "    # List to store the final models\n",
    "    final_models_ls = []\n",
    "\n",
    "    # Use the same params here you used in cross-validation\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse'\n",
    "      }\n",
    "\n",
    "    # Iterate through each set of cross-validation results and corresponding training targets\n",
    "    for cv_results, y_train in zip(cv_results_ls, y_train_ls):\n",
    "        # Determine the optimal number of boosting rounds from cross-validation results\n",
    "        optimal_boost_rounds = cv_results['test-rmse-mean'].idxmin() + 1\n",
    "\n",
    "        # Initialize the XGBoost regressor with determined parameters\n",
    "        final_model = xgb.XGBRegressor(\n",
    "            n_estimators=optimal_boost_rounds,\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        # Train the model on the full training dataset\n",
    "        final_model.fit(X_train_mod, y_train)\n",
    "\n",
    "        # Append the trained model to the list\n",
    "        final_models_ls.append(final_model)\n",
    "\n",
    "\n",
    "    if os.path.isdir('models')!=True:\n",
    "        os.mkdir('models')\n",
    "    #os.mkdir('models')\n",
    "    # Save each model with a unique filename\n",
    "    for idx, final_model in enumerate(final_models_ls):\n",
    "        filename = f'models/{fermi_lc_file}_batch_demand_forecaster_model_{idx+1}.pkl'  # Create a unique filename for each model\n",
    "        joblib.dump(final_model, filename)\n",
    "    del dtrain,cv_results\n",
    "    print(\"Ran!\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c4ddeaf-45bf-421e-85f6-5362fc877629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292\n",
      "Last mean RMSE: 0    0.426848\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 0    0.425569\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 0    0.427518\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Ran!\n",
      "66\n",
      "Last mean RMSE: 0    0.284059\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 39    0.260099\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 24    0.262929\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Ran!\n",
      "88\n",
      "Last mean RMSE: 6    0.444411\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 1    0.440206\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 0    0.449001\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Ran!\n",
      "61\n",
      "Last mean RMSE: 9    0.364509\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 1    0.369583\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 7    0.377478\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Ran!\n",
      "389\n",
      "Last mean RMSE: 30    0.900643\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 2    0.910795\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 4    0.901707\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Ran!\n",
      "120\n",
      "Last mean RMSE: 0    3.113713e+09\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 0    3.113774e+09\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 0    3.066279e+09\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Ran!\n",
      "200\n",
      "Last mean RMSE: 0    0.841565\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 0    0.836513\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 0    0.932341\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Ran!\n",
      "134\n",
      "Last mean RMSE: 0    0.442672\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 0    0.429205\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 0    0.442019\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Ran!\n",
      "190\n",
      "Last mean RMSE: 6    0.419294\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 23    0.417392\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 58    0.405547\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Ran!\n",
      "372\n",
      "Last mean RMSE: 12    0.478005\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 28    0.471221\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 14    0.474789\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Ran!\n",
      "190\n",
      "Last mean RMSE: 0    132.732799\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 8    108.85668\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 6    132.556174\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Ran!\n",
      "102\n",
      "Last mean RMSE: 24    0.405015\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 7    0.385813\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 0    0.39431\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Ran!\n",
      "145\n",
      "Last mean RMSE: 0    0.323571\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 0    0.31811\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 0    0.319183\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Ran!\n",
      "297\n",
      "Last mean RMSE: 0    785.769096\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 0    786.322484\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 0    789.857842\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Ran!\n",
      "118\n",
      "Last mean RMSE: 0    0.196121\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 9    0.196774\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 0    0.196135\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Ran!\n",
      "68\n",
      "Last mean RMSE: 0    0.195899\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 0    0.195896\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 0    0.190518\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Ran!\n",
      "346\n",
      "Last mean RMSE: 17    0.552554\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 30    0.533676\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 26    0.548937\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Ran!\n",
      "200\n",
      "Last mean RMSE: 41    1.239651\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 99    0.859489\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 64    1.094877\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Ran!\n",
      "212\n",
      "Last mean RMSE: 0    42092.941326\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 0    41749.901929\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 1    41715.680185\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Ran!\n",
      "143\n",
      "Last mean RMSE: 0    0.325412\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 0    0.332215\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Last mean RMSE: 0    0.330735\n",
      "Name: test-rmse-mean, dtype: float64\n",
      "Ran!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for indi_i_val in range(len(saved_fermi_lcs)):\n",
    "    if make_training_files==False:\n",
    "        continue\n",
    "    id = \"v1\"\n",
    "    a = train_model(saved_fermi_lcs[indi_i_val][-24:-7],directory,id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6aaada-a074-4e2f-bb14-d37c5bdb67ed",
   "metadata": {},
   "source": [
    "# Now we Predict!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef962594-2ed6-4193-be0d-8ba3e6f7faa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run predictions with all three models\n",
    "\n",
    "for indi_i_val in range(len(saved_fermi_lcs)):\n",
    "    predictions_ls = [] # list to store predictions\n",
    "    #if indi_i_val!=0:\n",
    "    #    continue\n",
    "\n",
    "    \n",
    "    for idx in range(1, 4):  # Assuming there are 3 models\n",
    "        filename = f'models/{saved_fermi_lcs[indi_i_val][-24:-7]}_batch_demand_forecaster_model_{idx}.pkl'  # Create a unique filename for each model\n",
    "        model = joblib.load(filename)\n",
    "        prediction = model.predict(features_df)\n",
    "        predictions_ls.append(prediction)\n",
    "    # Let's compare to the true values!\n",
    "\n",
    "    targets_df = pd.read_csv(f'{directory}/{saved_fermi_lcs[indi_i_val][-24:-7]}_targets_{id}.csv')\n",
    "    targets_df.set_index('#MJD', inplace=True) #This replaces the index with the MJD value\n",
    "\n",
    "    predictions_df = pd.DataFrame({f'predicted_{i+1}d': predictions_ls[i] for i in range(len(predictions_ls))})\n",
    "    predictions_df.index = features_df.index\n",
    "    result_df = predictions_df.join(targets_df, how = \"inner\")\n",
    "    #print(result_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc57443-8d58-4c1d-ba17-9a6b9cf0c95c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8a78ed0-ee66-4ba9-97f3-f757401db0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "font = {'size'   : 25}\n",
    "mpl.rc('font', **font) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0974b0d8-a83c-43c2-8067-a1081436d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(saved_fermi_lcs_arr,directory,id_val,target_val,predicted_val,example_source=\"none\"):\n",
    "    for indi_i_val in range(len(saved_fermi_lcs_arr)):\n",
    "        predictions_ls = [] # list to store predictions\n",
    "        if example_source!=\"none\":\n",
    "            if example_source!=saved_fermi_lcs[indi_i_val][-24:][:-7]:\n",
    "                continue\n",
    "\n",
    "        features_df = pd.read_csv(f'{directory}/{saved_fermi_lcs_arr[indi_i_val][-24:-7]}_features_{id_val}.csv')\n",
    "        features_df.set_index('#MJD', inplace=True) #This replaces the index with the MJD value\n",
    "        if len(features_df)/3>=40:\n",
    "            leave_number_indices = -40\n",
    "        else:\n",
    "            leave_number_indices = -1*int(len(features_df)/3)\n",
    "        \n",
    "        for idx in range(1, 4):  # Assuming there are 3 models\n",
    "            filename = f'models/{saved_fermi_lcs_arr[indi_i_val][-24:-7]}_batch_demand_forecaster_model_{idx}.pkl'  # Create a unique filename for each model\n",
    "            model = joblib.load(filename)\n",
    "            prediction = model.predict(features_df)\n",
    "            predictions_ls.append(prediction)\n",
    "        # Let's compare to the true values!\n",
    "\n",
    "        targets_df = pd.read_csv(f'{directory}/{saved_fermi_lcs_arr[indi_i_val][-24:-7]}_targets_{id_val}.csv')\n",
    "        targets_df.set_index('#MJD', inplace=True) #This replaces the index with the MJD value\n",
    "\n",
    "        predictions_df = pd.DataFrame({f'predicted_{i+1}d': predictions_ls[i] for i in range(len(predictions_ls))})\n",
    "        predictions_df.index = features_df.index\n",
    "        result_df = predictions_df.join(targets_df, how = \"inner\")\n",
    "        #print(result_df)\n",
    "    \n",
    "        fig = plt.figure(figsize=(12,7),dpi=200)\n",
    "        ax = plt.subplot()\n",
    "\n",
    "        ax.plot(result_df.index.array,result_df[target_val].array,\"-\",color=\"grey\",linewidth=3,label=\"Original Data\")\n",
    "        ax.plot(result_df.index.array,result_df[predicted_val].array,\":\",color=\"red\",linewidth=2,label=\"Training+Predicted Data\")\n",
    "        ax.plot([result_df.index.array[leave_number_indices],result_df.index.array[leave_number_indices]],[-0.05,10.15],\"--\",color=\"blue\")  #For example agnstorm\n",
    "\n",
    "        plt.ticklabel_format(axis='both', style='plain', scilimits=(4,9))\n",
    "\n",
    "    \n",
    "        plt.text(result_df.index.array[int(-1*leave_number_indices/2)],9.5,\"Training\")  #For  example\n",
    "        plt.text(result_df.index.array[leave_number_indices+3],9.5,\"Prediction\") #For  example\n",
    "\n",
    "        plt.xlabel(\"Time (MJD)\")\n",
    "        plt.ylabel(\"Count rate\")\n",
    "    \n",
    "        plt.ylim(-0.05,10.15) #For  example\n",
    "        plt.xlim(result_df.index.array[0]-0.5,result_df.index.array[-1]+11) #For   example\n",
    "        #ax.set_xticklabels([str(int(x)) for x in ax.get_xticks()])\n",
    "        plt.legend()\n",
    "\n",
    "        plt.savefig(f'predictions/{saved_fermi_lcs_arr[indi_i_val][-24:-7]}_{target_val}.pdf',bbox_inches=\"tight\")\n",
    "\n",
    "        plt.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "579849fb-48cd-417f-bb2e-f54f6c895641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making all points for 1 day targets:\n",
    "make_plot(saved_fermi_lcs,directory,id,'target_1d','predicted_1d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b06e552-3ae0-49d7-a681-089aa99937e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making all points for 2 day targets:\n",
    "make_plot(saved_fermi_lcs,directory,id,'target_2d','predicted_2d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d88cefaa-aa33-45a2-883e-57376453f013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making all points for 3 day targets:\n",
    "make_plot(saved_fermi_lcs,directory,id,'target_3d','predicted_3d')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77afd96b-95be-4000-b011-aa8d74f3f1b3",
   "metadata": {},
   "source": [
    "## Example\n",
    "To check an example, we will use one of the sources for which there exists a good amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac27682f-bd02-43d3-96b0-821cf6123afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "4FGL_J1058.6-8003\n",
    "\n",
    "# Making an example plot using 3 day targets for one source:\n",
    "make_plot(saved_fermi_lcs,directory,id,'target_3d','predicted_3d')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1299554d-6fbc-4089-bf62-878af36587b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
